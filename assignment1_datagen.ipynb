{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Library imports\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data_generator import generate_data\n",
    "\n",
    "dataset_2 = generate_data(dim=2, k=3, n_per_cluster=100, radius=7, cluster_dim=2, has_noise=True, n_noise=100)\n",
    "dataset_4 = generate_data(dim=4, k=4, n_per_cluster=100, radius=6, cluster_dim=3, has_noise=True, n_noise=150)\n",
    "dataset_10 = generate_data(dim=10, k=5, n_per_cluster=100, radius=5, cluster_dim=5, has_noise=True, n_noise=200)\n",
    "dataset_20 = generate_data(dim=20, k=5, n_per_cluster=100, radius=4, cluster_dim=7, has_noise=True, n_noise=200)\n",
    "dataset_100 = generate_data(dim=100, k=10, n_per_cluster=100, radius=3, cluster_dim=20, has_noise=False, n_noise=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each dataset, we chose a receding radius for the clusters. This means that the clusters are more dense in the center and less dense towards the edges. This is done to better visualize the curse of dimensionality. The noise points are uniformly distributed in the dataset.\n",
    "\n",
    "As the total dimensionality increases, we also increase the amount of clusters in the dataset, as well as the number of noise points.\n",
    "\n",
    "To better visualize the curse of dimensionality, we will omit the noise points in the final dataset (100 dimensions) completely. As will be seen in the plots below, even then we will be unable to see the clusters in that dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the datasets to csv files\n",
    "dataset_2_df = pd.DataFrame(dataset_2)\n",
    "dataset_2_df.to_csv(\"dataset_2.csv\", index=False)\n",
    "\n",
    "dataset_4_df = pd.DataFrame(dataset_4)\n",
    "dataset_4_df.to_csv(\"dataset_4.csv\", index=False)\n",
    "\n",
    "dataset_10_df = pd.DataFrame(dataset_10)\n",
    "dataset_10_df.to_csv(\"dataset_10.csv\", index=False)\n",
    "\n",
    "dataset_20_df = pd.DataFrame(dataset_20)\n",
    "dataset_20_df.to_csv(\"dataset_20.csv\", index=False)\n",
    "\n",
    "dataset_100_df = pd.DataFrame(dataset_100)\n",
    "dataset_100_df.to_csv(\"dataset_100.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
